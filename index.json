
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"Alessandro Canevaro is a T.I.M.E. (Top International Managers in Engineering) double degree student doing the MSc in Control Systems Engineering at the University of Padua and the MSc in Computer Science and Engineering at the Technical University of Denmark. He is mainly focusing on Artificial Intelligence and Algorithms for Computer Vision and Robotics. He is an ambitious and hardworking person who is always eager to learn new things\nDownload my resumé.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Alessandro Canevaro is a T.I.M.E. (Top International Managers in Engineering) double degree student doing the MSc in Control Systems Engineering at the University of Padua and the MSc in Computer Science and Engineering at the Technical University of Denmark.","tags":null,"title":"Alessandro Canevaro","type":"authors"},{"authors":null,"categories":null,"content":"Activity goal The objective of the final project is to detect, track, predict, and classify moving objects, whether they are occluded or unoccluded. In our scenario, we are given a stereo camera setup looking over a conveyor belt. Random objects are placed at one end of the conveyor belt at regular intervals. This simulates a general-purpose case where these objects need to have their attributes recognized in real-time. The main steps required to achieve our project objectives are:\nCamera Calibration and Rectification Object Detection and Tracking Object Classification ","date":1651795200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651795200,"objectID":"f235b70ab4a929a937385ab313bd1a9f","permalink":"https://alessandro-canevaro.github.io/project/perception/","publishdate":"2022-05-06T00:00:00Z","relpermalink":"/project/perception/","section":"project","summary":"Designing and implementation of a computer vision algorithm to track and estimate the position of obejcts.","tags":["Computer Vision"],"title":"Object Tracking and Classification","type":"project"},{"authors":null,"categories":null,"content":"Overall goal of the project The main goal of this project is to apply what we have learned in this course about MLOps to a simple machine/deep learning problem. We aim to make our whole pipeline as understandable and efficient as possible, using the tools we have been given - having good and clear structure and setup, adding comments to the code to make it easier to understand and so on. We will tackle an image classification problem and try to get as good results as possible, given our timeframe.\nWhat framework are you going to use It was decided to use the Kornia framework as it was deemed the best suited for this project which involves image classification.\nHow to you intend to include the framework into your project The main purpose of the Kornia framework in this project is data augmentation. The goal is to obtain a larger dataset, adding transformed images to the dataset we have already. Specifically, the focus is on the augmentation, the color, and the enhance modules of Kornia as these will provide all the necessary functions to manipulate the images (i.e. rotating, scaling, normalizing, etc.).\nWhat data are you going to run on Kaggle link:\nhttps://www.kaggle.com/grassknoted/asl-alphabet\nGeneral description:\nThe data set is a collection of images of hands signing the American Sign Language alphabet, separated in 29 folders which represent the various classes.\nSize:\nTrain data: 87,000 images, 200x200 pixels each. Test data: 29 images. Classes:\n26 for the letters A-Z. 3 classes for SPACE, DELETE and NOTHING. What deep learning models do you expect to use We will use mostly CNN (convolutional neural networks). Our focus will be on the overall architecture and parameters of our network (number of layers, padding, strides, max-pooling etc.).\n","date":1642723200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642723200,"objectID":"1326c32ae02e91529843c3c3a0969bcd","permalink":"https://alessandro-canevaro.github.io/project/mlops/","publishdate":"2022-01-21T00:00:00Z","relpermalink":"/project/mlops/","section":"project","summary":"Develop a deep learning model for the sign language recognition problem with a focus on CI/CD pipelines on GitHub, automated testing, training monitoring, data visualization, and cloud deployment.","tags":["Machine Learning"],"title":"Machine Learning Operation","type":"project"},{"authors":null,"categories":null,"content":"Activity goal The focus of this project is to identify if a wearable device can be used to reduce the spreading rate of COVID-19 by tracking a person’s body temperature and oxygen saturation in the blood in order to determine with a certain probability whether or not she might be infected, and if that is the case, warn her as well as the others in close proximity.\n","date":1638576000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638576000,"objectID":"82708a8daf0aa9fb48bea07025489c30","permalink":"https://alessandro-canevaro.github.io/project/mbse/","publishdate":"2021-12-04T00:00:00Z","relpermalink":"/project/mbse/","section":"project","summary":"Development of a Python simulator for analysing the effectiveness of a wearable device in tracking the spread of respiratory diseases.","tags":["Complex Systems","Other"],"title":"Disease Tracker","type":"project"},{"authors":null,"categories":null,"content":"Activity goal This project focuses on the development of software for a simulated robotic system, Turtlebot 3. This system should be capable of navigating a mostly predefined operational environment and to identify targets using information coming from QR codes. The environment is mostly predefined however the obstacles and targets, QR codes, can be spawned in pseudo random locations.\nThere will always be five QR codes, which spawn in the predefined operational area, however, the specific location of these QR codes will not be the same all the time. All QR codes contain four attributes. The attributes are the coordinates of the current QR target, the coordinates of the next QR target, and the ID of the QR code, which can be anywhere from 1 to 5. Lastly, a letter is also an attribute and these must be structured in the correct order in order to extract a message. Furthermore, the last QR code, i.e. the QR code number 5, has, as the next qr code coordinates, the coordinates of the first QR code.\n","date":1638230400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638230400,"objectID":"f13d231271ea72434da9ff5d6ec7b9aa","permalink":"https://alessandro-canevaro.github.io/project/ros/","publishdate":"2021-11-30T00:00:00Z","relpermalink":"/project/ros/","section":"project","summary":"Autonomous navigation of Turtlebot 3 robotic system.","tags":["Robotics"],"title":"Robot Operating System (ROS)","type":"project"},{"authors":null,"categories":null,"content":"Activity goal The aim is to develop a computer vision algorithm that can detect boats in an image. Specifically, it should draw a rectangular bounding box around each founded boat, and it should work correctly even when the image has no boats in it. Note that boats can appear from any perspective, and they can be very different: from small dinghies to cruise ships. The intersection over union (IoU) metric is used on the provided test images to measure the algorithm’s performance.\nAdopted approach Due to the great variety of boats and the availability of a large data set of images, a machine learning approach seems promising. Hence the use of a neural network in the proposed solution. In particular, the developed algorithm initially extracts features (key points and descriptors) from the image, then classifies the descriptors as boat/non-boat, and lastly, builds the bounding boxes. The last step is, in turn, composed of several sub-steps. The algorithm first generates a probability density function (PDF) of the potential locations of the boats. The PDF modes are then clustered using the mean shift algorithm, and finally, the bounding boxes are generated with a simple iterative procedure. The complete algorithm is here summarized:\nExtract features key points and descriptors from the to-be-detected image. Classify each descriptor as boat/non-boat using the trained classifier. Generate the probability map of the possible positions of the boats. Find and cluster the modes of the above probability density using the mean shift algorithm. Prune and suppress “weak” clusters. For each cluster, generate the bounding box. ","date":1626998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626998400,"objectID":"1ee69e7af9c35af9c419f73bbd6c7791","permalink":"https://alessandro-canevaro.github.io/project/boats/","publishdate":"2021-07-23T00:00:00Z","relpermalink":"/project/boats/","section":"project","summary":"Designing and implementation of a computer vision algorithm to detect boats using C++ and OpenCV.","tags":["Computer Vision"],"title":"Image Detection","type":"project"},{"authors":null,"categories":null,"content":"Activity goal After having derived the equations of motion for the SCARA robot, 2 constrol solutions were designed, implemented and tested in MATLAB and simulink for trajectory tracking purposes. Specifically the first is a PD with gravity compensation controller, while the second one is a Feedback linearization controller.\n","date":1623542400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623542400,"objectID":"c7f1f9d2707260576ec0f0d7318b9ed7","permalink":"https://alessandro-canevaro.github.io/project/scara/","publishdate":"2021-06-13T00:00:00Z","relpermalink":"/project/scara/","section":"project","summary":"Modelling and designing a control system for the SCARA robot","tags":["Robotics"],"title":"Control of the SCARA robot","type":"project"}]